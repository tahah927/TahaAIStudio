const express = require('express');
const axios = require('axios');
const { v4: uuidv4 } = require('uuid');

const router = express.Router();

// Middleware para obtener io
const getIO = (req) => req.app.get('io');

// ConfiguraciÃ³n de personalidad de Tech
const TECH_PERSONALITY = {
  name: "Tech",
  role: "Agente de IA especializado y amigable",
  personality: `Eres Tech, un agente de inteligencia artificial avanzado y todo en uno. Tu personalidad es:

CARACTERÃSTICAS PRINCIPALES:
- Profesional pero amigable y cercano
- Proactivo y siempre dispuesto a ayudar
- Experto en tecnologÃ­a, programaciÃ³n, creatividad y automatizaciÃ³n
- Capaz de adaptarte al estilo de comunicaciÃ³n del usuario
- Entusiasta por resolver problemas complejos

CAPACIDADES ESPECIALES:
- Generar imÃ¡genes con DALL-E
- Crear videos completos con IA
- Escribir cÃ³digo en mÃºltiples lenguajes
- Automatizar tareas complejas
- Explicar conceptos tÃ©cnicos de forma clara

ESTILO DE COMUNICACIÃ“N:
- Usa emojis ocasionalmente para ser mÃ¡s expresivo
- SÃ© conciso pero completo en tus respuestas
- Ofrece ejemplos prÃ¡cticos cuando sea relevante
- Pregunta por clarificaciones cuando sea necesario
- Sugiere funcionalidades adicionales cuando sea apropiado

IMPORTANTE:
- Siempre mantÃ©n un tono positivo y constructivo
- Si no puedes hacer algo, explica por quÃ© y ofrece alternativas
- Recuerda que puedes realizar tareas especÃ­ficas usando mis funciones integradas
- Adapta tu nivel tÃ©cnico segÃºn el usuario`
};

// Historial de conversaciones (en producciÃ³n usar base de datos)
const conversations = new Map();

// Chat general con GPT-4
router.post('/message', async (req, res) => {
  const taskId = uuidv4();
  const io = getIO(req);
  
  try {
    const { 
      message, 
      conversationId = 'default',
      context = {},
      model = 'gpt-4o-mini'
    } = req.body;

    if (!message) {
      return res.status(400).json({ error: 'El mensaje es requerido' });
    }

    console.log(`ðŸ’¬ [${taskId}] Nuevo mensaje en conversaciÃ³n ${conversationId}`);

    // Obtener o crear conversaciÃ³n
    if (!conversations.has(conversationId)) {
      conversations.set(conversationId, {
        id: conversationId,
        messages: [{
          role: 'system',
          content: TECH_PERSONALITY.personality
        }],
        createdAt: new Date(),
        lastActivity: new Date()
      });
    }

    const conversation = conversations.get(conversationId);
    
    // Agregar mensaje del usuario
    conversation.messages.push({
      role: 'user',
      content: message,
      timestamp: new Date()
    });

    // Agregar contexto si estÃ¡ disponible
    let contextualMessage = message;
    if (context.currentFunction) {
      contextualMessage = `[Contexto: Usuario estÃ¡ en la funciÃ³n ${context.currentFunction}] ${message}`;
    }

    io.to(taskId).emit('task-progress', {
      taskId,
      progress: 30,
      message: 'Procesando tu mensaje...'
    });

    // Llamar a OpenAI
    const response = await axios.post(
      `${process.env.OPENAI_API_URL}/chat/completions`,
      {
        model: model,
        messages: [
          ...conversation.messages.slice(0, -1), // Todos menos el Ãºltimo
          {
            role: 'user',
            content: contextualMessage
          }
        ],
        max_tokens: 1000,
        temperature: 0.7,
        presence_penalty: 0.1,
        frequency_penalty: 0.1
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        },
        timeout: 30000
      }
    );

    const assistantMessage = response.data.choices[0].message.content;

    // Agregar respuesta del asistente
    conversation.messages.push({
      role: 'assistant',
      content: assistantMessage,
      timestamp: new Date()
    });

    conversation.lastActivity = new Date();

    // Mantener solo los Ãºltimos 20 mensajes para evitar exceder lÃ­mites
    if (conversation.messages.length > 21) { // +1 por el mensaje del sistema
      conversation.messages = [
        conversation.messages[0], // Mantener mensaje del sistema
        ...conversation.messages.slice(-20)
      ];
    }

    io.to(taskId).emit('task-complete', {
      taskId,
      message: 'Respuesta generada'
    });

    console.log(`âœ… [${taskId}] Respuesta generada para conversaciÃ³n ${conversationId}`);

    res.json({
      success: true,
      taskId,
      response: {
        message: assistantMessage,
        conversationId,
        timestamp: new Date().toISOString(),
        model: model,
        usage: response.data.usage
      }
    });

  } catch (error) {
    console.error(`âŒ [${taskId}] Error en chat:`, error.response?.data || error.message);
    
    io.to(taskId).emit('task-error', {
      taskId,
      message: 'Error al procesar el mensaje'
    });

    res.status(500).json({ 
      error: 'Error al procesar el mensaje',
      details: error.response?.data?.error?.message || error.message,
      taskId
    });
  }
});

// Obtener historial de conversaciÃ³n
router.get('/conversation/:conversationId', async (req, res) => {
  try {
    const { conversationId } = req.params;
    const { limit = 50, offset = 0 } = req.query;

    if (!conversations.has(conversationId)) {
      return res.status(404).json({ error: 'ConversaciÃ³n no encontrada' });
    }

    const conversation = conversations.get(conversationId);
    
    // Filtrar mensaje del sistema y aplicar paginaciÃ³n
    const messages = conversation.messages
      .filter(msg => msg.role !== 'system')
      .slice(offset, offset + parseInt(limit));

    res.json({
      success: true,
      conversation: {
        id: conversationId,
        messages: messages,
        totalMessages: conversation.messages.length - 1, // -1 por el mensaje del sistema
        createdAt: conversation.createdAt,
        lastActivity: conversation.lastActivity
      }
    });

  } catch (error) {
    console.error('Error obteniendo conversaciÃ³n:', error);
    res.status(500).json({ 
      error: 'Error al obtener la conversaciÃ³n',
      details: error.message
    });
  }
});

// Listar conversaciones
router.get('/conversations', async (req, res) => {
  try {
    const { limit = 20, offset = 0 } = req.query;

    const conversationList = Array.from(conversations.values())
      .map(conv => ({
        id: conv.id,
        lastMessage: conv.messages[conv.messages.length - 1]?.content?.substring(0, 100) + '...',
        messageCount: conv.messages.length - 1, // -1 por el mensaje del sistema
        createdAt: conv.createdAt,
        lastActivity: conv.lastActivity
      }))
      .sort((a, b) => new Date(b.lastActivity) - new Date(a.lastActivity))
      .slice(offset, offset + parseInt(limit));

    res.json({
      success: true,
      conversations: conversationList,
      total: conversations.size
    });

  } catch (error) {
    console.error('Error listando conversaciones:', error);
    res.status(500).json({ 
      error: 'Error al listar conversaciones',
      details: error.message
    });
  }
});

// Crear nueva conversaciÃ³n
router.post('/conversation', async (req, res) => {
  try {
    const { name, initialMessage } = req.body;
    const conversationId = uuidv4();

    const conversation = {
      id: conversationId,
      name: name || `ConversaciÃ³n ${new Date().toLocaleDateString()}`,
      messages: [{
        role: 'system',
        content: TECH_PERSONALITY.personality
      }],
      createdAt: new Date(),
      lastActivity: new Date()
    };

    // Si hay mensaje inicial, procesarlo
    if (initialMessage) {
      conversation.messages.push({
        role: 'user',
        content: initialMessage,
        timestamp: new Date()
      });

      // Generar respuesta inicial
      try {
        const response = await axios.post(
          `${process.env.OPENAI_API_URL}/chat/completions`,
          {
            model: 'gpt-4o-mini',
            messages: conversation.messages,
            max_tokens: 500,
            temperature: 0.7
          },
          {
            headers: {
              'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
              'Content-Type': 'application/json'
            }
          }
        );

        conversation.messages.push({
          role: 'assistant',
          content: response.data.choices[0].message.content,
          timestamp: new Date()
        });
      } catch (error) {
        console.error('Error generando respuesta inicial:', error);
      }
    }

    conversations.set(conversationId, conversation);

    console.log(`ðŸ’¬ Nueva conversaciÃ³n creada: ${conversationId}`);

    res.json({
      success: true,
      conversation: {
        id: conversationId,
        name: conversation.name,
        createdAt: conversation.createdAt,
        messageCount: conversation.messages.length - 1
      }
    });

  } catch (error) {
    console.error('Error creando conversaciÃ³n:', error);
    res.status(500).json({ 
      error: 'Error al crear conversaciÃ³n',
      details: error.message
    });
  }
});

// Eliminar conversaciÃ³n
router.delete('/conversation/:conversationId', async (req, res) => {
  try {
    const { conversationId } = req.params;

    if (!conversations.has(conversationId)) {
      return res.status(404).json({ error: 'ConversaciÃ³n no encontrada' });
    }

    conversations.delete(conversationId);

    console.log(`ðŸ—‘ï¸ ConversaciÃ³n eliminada: ${conversationId}`);

    res.json({
      success: true,
      message: 'ConversaciÃ³n eliminada exitosamente',
      conversationId
    });

  } catch (error) {
    console.error('Error eliminando conversaciÃ³n:', error);
    res.status(500).json({ 
      error: 'Error al eliminar conversaciÃ³n',
      details: error.message
    });
  }
});

// Generar sugerencias de respuesta
router.post('/suggestions', async (req, res) => {
  try {
    const { conversationId, context } = req.body;

    if (!conversations.has(conversationId)) {
      return res.status(404).json({ error: 'ConversaciÃ³n no encontrada' });
    }

    const conversation = conversations.get(conversationId);
    const lastMessages = conversation.messages.slice(-5); // Ãšltimos 5 mensajes

    const response = await axios.post(
      `${process.env.OPENAI_API_URL}/chat/completions`,
      {
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: 'Genera 3 sugerencias cortas de preguntas o temas que el usuario podrÃ­a querer explorar basÃ¡ndote en la conversaciÃ³n. Cada sugerencia debe ser una pregunta o solicitud especÃ­fica de mÃ¡ximo 10 palabras.'
          },
          ...lastMessages
        ],
        max_tokens: 150,
        temperature: 0.8
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    const suggestionsText = response.data.choices[0].message.content;
    const suggestions = suggestionsText
      .split('\n')
      .filter(line => line.trim())
      .map(line => line.replace(/^\d+\.\s*/, '').trim())
      .slice(0, 3);

    res.json({
      success: true,
      suggestions
    });

  } catch (error) {
    console.error('Error generando sugerencias:', error);
    res.status(500).json({ 
      error: 'Error al generar sugerencias',
      details: error.message
    });
  }
});

// Buscar en conversaciones
router.get('/search', async (req, res) => {
  try {
    const { query, conversationId, limit = 20 } = req.query;

    if (!query) {
      return res.status(400).json({ error: 'Query de bÃºsqueda requerido' });
    }

    const results = [];
    const searchQuery = query.toLowerCase();

    // Buscar en conversaciÃ³n especÃ­fica o en todas
    const conversationsToSearch = conversationId 
      ? [conversations.get(conversationId)].filter(Boolean)
      : Array.from(conversations.values());

    for (const conversation of conversationsToSearch) {
      const matchingMessages = conversation.messages
        .filter(msg => msg.role !== 'system')
        .filter(msg => msg.content.toLowerCase().includes(searchQuery))
        .map(msg => ({
          conversationId: conversation.id,
          message: msg.content,
          role: msg.role,
          timestamp: msg.timestamp,
          preview: msg.content.substring(0, 200) + '...'
        }));

      results.push(...matchingMessages);
    }

    // Ordenar por relevancia (mÃ¡s recientes primero)
    results.sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));

    res.json({
      success: true,
      results: results.slice(0, parseInt(limit)),
      total: results.length,
      query
    });

  } catch (error) {
    console.error('Error en bÃºsqueda:', error);
    res.status(500).json({ 
      error: 'Error en la bÃºsqueda',
      details: error.message
    });
  }
});

// Limpiar conversaciones antiguas (tarea de mantenimiento)
router.post('/cleanup', async (req, res) => {
  try {
    const { daysOld = 30 } = req.body;
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - daysOld);

    let deletedCount = 0;

    for (const [id, conversation] of conversations.entries()) {
      if (conversation.lastActivity < cutoffDate) {
        conversations.delete(id);
        deletedCount++;
      }
    }

    console.log(`ðŸ§¹ Limpieza completada: ${deletedCount} conversaciones eliminadas`);

    res.json({
      success: true,
      message: `${deletedCount} conversaciones antiguas eliminadas`,
      deletedCount,
      remainingCount: conversations.size
    });

  } catch (error) {
    console.error('Error en limpieza:', error);
    res.status(500).json({ 
      error: 'Error en la limpieza',
      details: error.message
    });
  }
});

module.exports = router;